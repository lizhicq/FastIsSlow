convert.py --outfile models/13B/ggml-model-f16.bin --outtype f16 ../meta-models/llama-2-13b-chat